---
layout: post
title: "Chain-of-Thought의 한계: 만능 추론 도구는 없다"
date: 2025-08-13
categories: [paper-review]
tags: [Chain-of-Thought, LLM, 추론, 논문리뷰, AI한계]
lang: ko
description: "Chain-of-Thought 프롬프팅의 발전 과정과 한계를 지적하는 최신 논문들을 심층 분석하며, CoT가 직면한 근본적 문제점들을 탐구합니다."
---

## 들어가며

Chain-of-Thought(CoT) 프롬프팅은 2022년 구글의 Jason Wei 연구팀이 발표한 이후 대규모 언어모델의 추론 능력을 향상시키는 혁신적 기법으로 주목받아왔습니다. 복잡한 문제를 단계별로 해결하는 중간 추론 과정을 보여줌으로써 모델의 성능을 극적으로 개선할 수 있다는 결과는 AI 업계에 큰 충격을 주었습니다.

하지만 최근 연구들은 CoT의 한계와 문제점을 지적하기 시작했습니다. 2024년과 2025년에 발표된 두 편의 중요한 논문을 통해 CoT가 생각만큼 만능이 아니며, 특정 상황에서는 오히려 성능 저하를 가져올 수 있음이 밝혀졌습니다. 이번 포스트에서는 CoT의 발전 과정과 함께 이러한 한계를 지적하는 연구들을 심층 분석해보겠습니다.

## Chain-of-Thought의 등장과 성공

### 혁신적 아이디어의 탄생

Chain-of-Thought 프롬프팅은 2022년 1월 Google Research의 Jason Wei, Xuezhi Wang, Dale Schuurmans 등이 발표한 논문 "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"에서 처음 소개되었습니다.

이 기법의 핵심 아이디어는 단순하지만 강력합니다. 기존의 few-shot 프롬프팅이 단순히 입력-출력 쌍만을 제시했다면, CoT는 중간 추론 단계(intermediate reasoning steps)를 포함하여 모델이 "생각하는 과정"을 보여주는 것입니다.

예를 들어, 기존 방식:
```
Q: 카페에 23명이 있었는데, 7명이 나가고 5명이 들어왔다면 지금 몇 명인가?
A: 21명

Q: 학교에 328명의 학생이 있는데...
```

CoT 방식:
```
Q: 카페에 23명이 있었는데, 7명이 나가고 5명이 들어왔다면 지금 몇 명인가?
A: 처음에 23명이 있었습니다. 7명이 나갔으므로 23 - 7 = 16명이 남았습니다. 
그리고 5명이 들어왔으므로 16 + 5 = 21명입니다.

Q: 학교에 328명의 학생이 있는데...
```

### 놀라운 성능 향상

Wei 등의 연구에서 CoT는 세 가지 주요 영역에서 뛰어난 성과를 보였습니다:

1. **산술 추론(Arithmetic Reasoning)**: GSM8K 수학 문제 벤치마크에서 540B 파라미터 모델이 단 8개의 CoT 예시만으로 기존 최고 성능을 뛰어넘었습니다.

2. **상식 추론(Commonsense Reasoning)**: 일상적 상황에 대한 추론에서도 일관된 성능 향상을 보였습니다.

3. **기호 추론(Symbolic Reasoning)**: 논리적 규칙과 패턴을 다루는 문제에서 특히 두드러진 개선을 보였습니다.

### 업계의 광범위한 채택

CoT의 성공은 빠르게 업계 전반으로 확산되었습니다. OpenAI의 GPT 시리즈, Anthropic의 Claude, Google의 Gemini 등 주요 LLM들이 CoT 기법을 적극 도입했습니다. 특히 복잡한 수학 문제, 논리 퍼즐, 다단계 추론이 필요한 작업에서 CoT는 거의 필수적인 도구로 여겨졌습니다.

## CoT의 한계를 드러낸 연구들

하지만 CoT의 화려한 성공 뒤에는 간과된 문제점들이 있었습니다. 2024년과 2025년에 발표된 두 편의 중요한 연구가 이러한 한계를 체계적으로 분석했습니다.

### 1. "The Curse of CoT" (2025)

#### 연구 개요

홍콩과학기술대학교의 Tianshi Zheng 팀이 2025년 4월에 발표한 "The Curse of CoT: On the Limitations of Chain-of-Thought in In-Context Learning"은 CoT의 근본적 한계를 다룬 대규모 연구입니다.

#### 실험 설계와 발견

연구팀은 16개의 최신 LLM과 9개의 패턴 기반 In-Context Learning(ICL) 데이터셋을 사용하여 광범위한 실험을 수행했습니다. 놀랍게도 결과는 기존 믿음과 정반대였습니다:

- **일관된 성능 저하**: CoT와 그 변형들(ReAct, Tree-of-Thought 등)이 직접 답변보다 일관되게 낮은 성능을 보였습니다.
- **모델 규모 무관**: 이러한 현상은 모델 크기나 벤치마크 복잡도와 무관하게 나타났습니다.
- **더 정교한 변형일수록 더 나쁜 성능**: ReAct, ToT 같은 고도화된 추론 프레임워크가 오히려 더 낮은 성능을 보였습니다.

#### 원인 분석: 명시적-암시적 이중성

연구팀은 이 현상의 원인을 "explicit-implicit duality(명시적-암시적 이중성)"로 설명했습니다:

1. **명시적 추론의 실패**: LLM들이 demonstration에서 근본적인 패턴을 추론하는 데 어려움을 겪습니다.

2. **암시적 추론의 방해**: CoT의 중간 설명이 맥락적 거리를 증가시켜 few-shot 학습 구조를 파괴합니다.

3. **노이즈 효과**: 약한 명시적 추론에서 발생하는 노이즈가 전체 추론 과정을 저해합니다.

### 2. "Chain of Thoughtlessness?" (2024)

#### 연구 개요

Arizona State University의 Kaya Stechly, Karthik Valmeekam, Subbarao Kambhampati가 2024년 5월에 발표한 "Chain of Thoughtlessness? An Analysis of CoT in Planning"은 계획(planning) 작업에서 CoT의 한계를 구체적으로 분석했습니다.

#### Blocksworld에서의 실험

연구팀은 고전적인 계획 도메인인 Blocksworld를 사용하여 CoT의 일반화 능력을 테스트했습니다. 결과는 충격적이었습니다:

1. **극도로 제한적인 일반화**: CoT가 의미 있는 성능 향상을 보인 경우는 프롬프트가 문제 클래스에 극도로 특화되어 있을 때뿐이었습니다.

2. **빠른 성능 악화**: 쿼리에서 지정된 스택의 크기가 예시보다 커지면 성능이 급격히 떨어졌습니다.

3. **알고리즘 학습의 실패**: CoT가 모델에게 일반적인 알고리즘적 절차를 가르치는 것이 아니라 고도로 문제별 특화된 프롬프트에 의존한다는 것이 밝혀졌습니다.

#### 다른 도메인에서의 검증

연구팀은 이전 CoT 연구들에서 자주 사용된 세 가지 도메인의 확장 가능한 변형을 만들어 실험했습니다. 결과는 동일한 실패 모드를 보여주었으며, 이는 Blocksworld에서 발견된 문제가 일반적인 현상임을 시사했습니다.

## CoT 한계의 근본적 원인

두 연구를 종합하면 CoT의 한계는 여러 층위에서 나타납니다:

### 1. 패턴 추론의 근본적 어려움

LLM들은 demonstration 쌍에서 근본적인 패턴이나 규칙을 추론하는 데 구조적 한계를 가지고 있습니다. 이는 단순히 모델 크기나 훈련 데이터의 문제가 아니라, 현재 transformer 아키텍처와 학습 방식의 근본적 한계로 보입니다.

### 2. 맥락적 거리 증가

CoT의 중간 설명은 demonstration과 최종 답안 사이의 "맥락적 거리"를 증가시킵니다. 이는 few-shot 학습의 핵심 메커니즘인 패턴 인식을 방해하여 오히려 성능 저하를 가져올 수 있습니다.

### 3. 추론 과정의 신뢰성 문제

CoT가 생성하는 중간 추론 단계가 실제로는 최종 답안과 인과적 관계가 없는 경우가 많습니다. 모델이 올바른 답을 내더라도 그 추론 과정은 결함이 있거나 심지어 논리적으로 잘못된 경우가 빈번합니다.

### 4. 일반화의 실패

CoT는 특정 문제 클래스에 고도로 특화된 프롬프트에서만 효과를 보이며, 문제가 조금만 변형되어도 성능이 급격히 떨어집니다. 이는 진정한 의미의 추론 능력 향상이 아니라 단순한 패턴 매칭에 가깝다는 것을 시사합니다.

## 실무적 함의와 대안 탐색

### 1. CoT 사용 시 주의사항

이러한 연구 결과는 CoT를 실무에서 사용할 때 다음과 같은 주의사항을 시사합니다:

- **문제 도메인의 명확한 정의**: CoT가 효과적인 특정 문제 유형을 명확히 식별해야 합니다.
- **일반화 한계 인식**: CoT의 성능이 프롬프트에 극도로 의존적임을 인식하고 과도한 일반화를 피해야 합니다.
- **검증 메커니즘 구축**: CoT의 추론 과정이 실제로 유효한지 별도의 검증 메커니즘이 필요합니다.

### 2. 대안적 접근법

CoT의 한계를 극복하기 위한 여러 대안이 제시되고 있습니다:

- **Hybrid 접근법**: 명시적 추론과 암시적 추론을 적절히 조합하는 방법
- **Domain-specific 최적화**: 특정 도메인에 특화된 추론 메커니즘 개발
- **검증 강화**: 추론 과정의 각 단계를 독립적으로 검증하는 시스템

## 미래 연구 방향

### 1. 추론의 메커니즘 이해

CoT의 한계를 극복하기 위해서는 먼저 LLM이 추론을 수행하는 근본적 메커니즘을 더 깊이 이해해야 합니다. 이는 다음과 같은 연구 영역을 포함합니다:

- **내부 표현 분석**: transformer의 attention 패턴과 내부 표현이 추론 과정에서 어떻게 작동하는지 분석
- **scaling law 재검토**: 모델 크기와 추론 능력 사이의 관계에 대한 새로운 이해
- **아키텍처 개선**: 추론에 더 적합한 새로운 아키텍처 탐색

### 2. 평가 방법론의 개선

현재의 벤치마크와 평가 방법론이 CoT의 진정한 능력을 측정하는 데 적합한지 재검토가 필요합니다:

- **일반화 능력 측정**: 문제 변형에 대한 robustness를 더 정확히 측정하는 방법
- **추론 과정 평가**: 최종 답안뿐만 아니라 추론 과정 자체의 품질을 평가하는 메트릭
- **도메인별 특화 평가**: 각 도메인의 특성을 반영한 평가 체계

### 3. 새로운 추론 패러다임

CoT를 넘어서는 새로운 추론 패러다임에 대한 연구가 활발히 진행되고 있습니다:

- **Tool-augmented reasoning**: 외부 도구와 연계한 추론 시스템
- **Multi-modal reasoning**: 텍스트, 이미지, 수식 등을 통합한 추론
- **Collaborative reasoning**: 여러 모델이 협력하는 추론 시스템

## 결론: 추론의 새로운 지평을 향해

Chain-of-Thought는 분명히 LLM 연구에 중요한 기여를 했습니다. 하지만 최근 연구들이 보여주듯이, CoT는 만능 해결책이 아니며 명확한 한계를 가지고 있습니다. "The Curse of CoT"와 "Chain of Thoughtlessness"는 이러한 한계를 체계적으로 분석하여 우리에게 중요한 통찰을 제공합니다.

핵심은 CoT를 맹목적으로 신뢰하는 것이 아니라, 그 한계를 인식하고 더 나은 추론 방법론을 개발하는 것입니다. 명시적-암시적 추론의 이중성, 패턴 추론의 근본적 어려움, 일반화의 실패 등은 모두 극복해야 할 과제들입니다.

앞으로의 연구는 이러한 한계를 인정하고 더 robust하고 일반화 가능한 추론 시스템을 개발하는 방향으로 나아가야 합니다. CoT의 실패는 끝이 아니라 새로운 시작입니다. 진정한 기계 추론을 향한 여정은 이제 막 시작된 것일지도 모릅니다.

---

**참고문헌**

- Wei, J., Wang, X., Schuurmans, D., et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. *arXiv preprint arXiv:2201.11903*.

- Zheng, T., Chen, Y., Li, C., et al. (2025). The Curse of CoT: On the Limitations of Chain-of-Thought in In-Context Learning. *arXiv preprint arXiv:2504.05081*.

- Stechly, K., Valmeekam, K., & Kambhampati, S. (2024). Chain of Thoughtlessness? An Analysis of CoT in Planning. *Advances in Neural Information Processing Systems 37 (NeurIPS 2024)*.